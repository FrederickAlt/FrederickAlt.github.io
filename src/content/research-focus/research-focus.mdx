---

---

I am a PhD candidate at University of MÃ¼nster, Germany focusing on Probability Theory in Machine Learning, Neural Network Training Dynamics.

My current research and PhD thesis focuses on understanding the training dynamics of ultra wide neural networks using **probability theory**. In particular, I study the emergence of the **Neural Tangent Kernel (NTK)** regime and the $\mu P$ regime as characterized by Greg Yang. I show that even in rich settings like the $\mu P$ regime the layers decouple stochastically for all training time. Furthermore I draw parallels to **lazy** and **rich** training regimes and the phenomenon of **Grokking**.


